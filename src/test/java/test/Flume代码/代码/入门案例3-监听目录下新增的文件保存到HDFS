#1、定义agent、source、channel、sink的名称
a1.sources = r1
a1.channels = c1
a1.sinks = k1
#2、描述source
a1.sources.r1.type = spooldir
#指定监控哪个目录
a1.sources.r1.spoolDir = /opt/module/flume/datas
#定义采集目录下符合要求的文件名的数据
a1.sources.r1.includePattern = ^.*\.log$
#定义采集的批次的大小<=事务的大小
a1.sources.r1.batchSize = 100

#3、描述channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 1000

#4、描述sink
a1.sinks.k1.type = hdfs
#定义hdfs数据的保存路径
a1.sinks.k1.hdfs.path = /flume/spool/%Y%m%d
#定义hdfs保存文件的前缀
a1.sinks.k1.hdfs.filePrefix = log-
#指定间隔多久滚动生成新文件
a1.sinks.k1.hdfs.rollInterval = 3600
#指定文件多大之后滚动生成新文件
a1.sinks.k1.hdfs.rollSize = 134210000
#指定文件写入多少个Event后滚动生成新文件
a1.sinks.k1.hdfs.rollCount = 0
#定义sink一个批次拉取多少数据，必须<=事务的容量
a1.sinks.k1.hdfs.batchSize = 100
#指定写入hdfs的时候数据的压缩格式
#a1.sinks.k1.hdfs.codeC = 100
#指定以什么文件格式写入hdfs[SequenceFile-序列化文件, DataStream-文本文件, CompressedStream-压缩文件]
a1.sinks.k1.hdfs.fileType = DataStream
#是否按照指定的时间间隔生成文件夹
a1.sinks.k1.hdfs.round = true
#指定生成文件夹的时间值
a1.sinks.k1.hdfs.roundValue = 24
#指定生成文件夹的时间单位
a1.sinks.k1.hdfs.roundUnit = hour
#是否使用本地的时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true

#5、关联source->channel->sink
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
